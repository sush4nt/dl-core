{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgDYQgkTqmLC"
      },
      "source": [
        "# 1. Importing Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBlwvHxTqlO8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qkjwrvUq6E6"
      },
      "source": [
        "# 2. Importing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-2X174lqrbJ",
        "outputId": "52b9cb75-b427-4e1d-ebd9-138666d54867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Before\n",
            "<class 'numpy.ndarray'>\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "After\n",
            "<class 'numpy.ndarray'>\n",
            "(60000, 28, 28, 1)\n",
            "(60000,)\n",
            "(10000, 28, 28, 1)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(\"Before\")\n",
        "print(type(x_train))\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "print(\"After\")\n",
        "print(type(x_train))\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu4M1aUlrKg0"
      },
      "source": [
        "## 2.1 Using classes to combine multiple layers into a single CNN Block that can be used multiple times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGRI-Y85zO6q"
      },
      "source": [
        "References:\n",
        "[What is the difference between __init__ and __call__](https://stackoverflow.com/questions/9663562/what-is-the-difference-between-init-and-call#:~:text=So%2C%20__init__%20is,initializing%20the%20instance%20variable%20also.&text=And%20__call__%20is,object%20like%20any%20other%20function.&text=Save%20this%20answer.,-Show%20activity%20on)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBx8GOrDrKAL"
      },
      "outputs": [],
      "source": [
        "# CNN -> BatchNorm -> ReLU (common structure)\n",
        "# x10 (a lot of code to write!)\n",
        "\n",
        "\n",
        "class CNNBlock(layers.Layer):\n",
        "    def __init__(self, out_channels, kernel_size=3):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        self.conv = layers.Conv2D(out_channels, kernel_size, padding=\"same\")\n",
        "        self.bn = layers.BatchNormalization()\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.conv(input_tensor)\n",
        "        x = self.bn(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        CNNBlock(32),\n",
        "        CNNBlock(64),\n",
        "        CNNBlock(128),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10)\n",
        "    ]\n",
        ")\n",
        "# print(model.summary())\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=keras.optimizers.Adam(),\n",
        "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#     metrics=[\"accuracy\"],\n",
        "# )\n",
        "\n",
        "# model.fit(x_train, y_train, batch_size=64, epochs=2, verbose=2)\n",
        "# model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LpAgd-CuLgw"
      },
      "outputs": [],
      "source": [
        "class ResBlock(layers.Layer):\n",
        "    def __init__(self, channels):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.cnn1 = CNNBlock(channels[0], 3)\n",
        "        self.cnn2 = CNNBlock(channels[1], 3)\n",
        "        self.cnn3 = CNNBlock(channels[2], 3)\n",
        "        self.pooling = layers.MaxPooling2D()\n",
        "        self.identity_mapping = layers.Conv2D(channels[1], 1, padding=\"same\")\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.cnn1(input_tensor, training=training)\n",
        "        x = self.cnn2(x, training=training)\n",
        "        x = self.cnn3(x + self.identity_mapping(input_tensor), training=training,)\n",
        "        x = self.pooling(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet_Like(keras.Model):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet_Like, self).__init__()\n",
        "        self.block1 = ResBlock([32, 32, 64])\n",
        "        self.block2 = ResBlock([128, 128, 256])\n",
        "        self.block3 = ResBlock([128, 256, 512])\n",
        "        self.pool = layers.GlobalAveragePooling2D()\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        x = self.block1(input_tensor, training=training)\n",
        "        x = self.block2(x, training=training)\n",
        "        x = self.block3(x, training=training)\n",
        "        x = self.pool(x, training=training)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def model(self):\n",
        "        x = keras.Input(shape=(28, 28, 1))\n",
        "        return keras.Model(inputs=[x], outputs=self.call(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVZoSNX7q9MF"
      },
      "outputs": [],
      "source": [
        "# # model = ResNet_Like().model()\n",
        "# # base_input = model.layers[0].input\n",
        "# # base_output = model.layers[2].output\n",
        "# # output = layers.Dense(10)(layers.Flatten()(base_output))\n",
        "# model = ResNet_Like(num_classes=10).model()\n",
        "# # model = keras.Model(base_input, output)\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=keras.optimizers.Adam(),\n",
        "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#     metrics=[\"accuracy\"],\n",
        "# )\n",
        "\n",
        "# model.fit(x_train, y_train, batch_size=64, epochs=2, verbose=2)\n",
        "# model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n",
        "# model.save(\"pretrained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH-9uLBE28ga",
        "outputId": "8e679c21-4634-43f6-cc24-ad8fd16e5347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 256), dtype=tf.float32, name=None), name='res_block_1/max_pooling2d_1/MaxPool:0', description=\"created by layer 'res_block_1'\")\n",
            "938/938 - 757s - loss: 0.1048 - accuracy: 0.9684 - 757s/epoch - 807ms/step\n",
            "157/157 - 33s - loss: 0.0472 - accuracy: 0.9853 - 33s/epoch - 213ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.047229740768671036, 0.9853000044822693]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ResNet_Like().model()\n",
        "base_input = model.layers[0].input\n",
        "base_output = model.layers[2].output\n",
        "print(base_input)\n",
        "print(base_output)\n",
        "output = layers.Dense(10)(layers.Flatten()(base_output))\n",
        "model = keras.Model(base_input, output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n",
        "# model.save(\"pretrained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNJca2k6rWDP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}