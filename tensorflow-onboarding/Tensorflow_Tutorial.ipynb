{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUyBvn_Q8zSv",
        "outputId": "d35f7f63-1ea3-43cc-fc16-537a87d4efc6"
      },
      "id": "pUyBvn_Q8zSv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "\n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEoWIlgx9U4-",
        "outputId": "581f2637-90bc-432d-d682-f4711077eefa"
      },
      "id": "JEoWIlgx9U4-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.6170942800000034\n",
            "GPU (s):\n",
            "0.048118093000027784\n",
            "GPU speedup over CPU: 75x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04a0347",
      "metadata": {
        "id": "a04a0347"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bf3b7e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bf3b7e9",
        "outputId": "cd9f4405-7db0-4c86-8f04-cda3bfcf7c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[4.]], shape=(1, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]], shape=(2, 3), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]], shape=(4, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0.]]], shape=(3, 2, 5), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.0540899  0.7809763 ]\n",
            " [0.7347256  0.12115991]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.56623864 -0.99144644 -0.84927344]\n",
            " [-0.23078705 -0.07150687  0.25640845]\n",
            " [ 0.90426153  1.27145088  0.42763475]], shape=(3, 3), dtype=float64)\n",
            "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Initialization\n",
        "x = tf.constant(4, shape=(1, 1), dtype=tf.float32)\n",
        "print(x)\n",
        "\n",
        "x = tf.constant([[1, 2, 3], [4, 5, 6]], shape=(2, 3))\n",
        "print(x)\n",
        "\n",
        "x = tf.eye(3)\n",
        "print(x)\n",
        "\n",
        "x = tf.ones((4, 3))\n",
        "print(x)\n",
        "\n",
        "x = tf.zeros((3, 2, 5))\n",
        "print(x)\n",
        "\n",
        "x = tf.random.uniform((2, 2), minval=0, maxval=1)\n",
        "print(x)\n",
        "\n",
        "x = tf.random.normal((3, 3), mean=0, stddev=1)\n",
        "print(tf.cast(x, dtype=tf.float64))\n",
        "# tf.float (16,32,64), tf.int (8, 16, 32, 64), tf.bool\n",
        "\n",
        "x = tf.range(9)\n",
        "x = tf.range(start=0, limit=10, delta=2)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef9a5267",
      "metadata": {
        "id": "ef9a5267",
        "outputId": "c6090e40-3b07-46e5-a14a-9c20faa6be77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10 10 10], shape=(3,), dtype=int32)\n",
            "tf.Tensor([-8 -6 -4], shape=(3,), dtype=int32)\n",
            "tf.Tensor([0.11111111 0.25       0.42857143], shape=(3,), dtype=float64)\n",
            "tf.Tensor([ 9 16 21], shape=(3,), dtype=int32)\n",
            "tf.Tensor(46, shape=(), dtype=int32)\n",
            "tf.Tensor([  1  32 243], shape=(3,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 2.063076   -0.44910747]\n",
            " [ 2.2348473  -1.0109867 ]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Math\n",
        "\n",
        "#element-wise operations\n",
        "x = tf.constant([1, 2, 3])\n",
        "y = tf.constant([9, 8, 7])\n",
        "\n",
        "z = tf.add(x, y)\n",
        "z = x + y\n",
        "print(z)\n",
        "\n",
        "z = tf.subtract(x, y)\n",
        "z = x - y\n",
        "print(z)\n",
        "\n",
        "z = tf.divide(x, y)\n",
        "z = x / y\n",
        "print(z)\n",
        "\n",
        "z = tf.multiply(x, y)\n",
        "z = x * y\n",
        "print(z)\n",
        "\n",
        "\n",
        "#element-wise multiplication and then summation\n",
        "z = tf.tensordot(x, y, axes=1)\n",
        "z = tf.reduce_sum(x*y, axis=0)\n",
        "print(z)\n",
        "\n",
        "\n",
        "z = x ** 5\n",
        "print(z)\n",
        "\n",
        "\n",
        "x = tf.random.normal((2, 3))\n",
        "y = tf.random.normal((3, 2))\n",
        "z = tf.matmul(x, y)\n",
        "z = x @ y\n",
        "print(z)\n",
        "\n",
        "x = tf.random.normal((2, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efc89cad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efc89cad",
        "outputId": "3760d3bd-5f41-460c-dfea-8dcbb31299ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 1 2 3 1 2 3], shape=(8,), dtype=int32)\n",
            "tf.Tensor([1 1 2 3 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 1], shape=(2,), dtype=int32)\n",
            "tf.Tensor([0 1 3 2], shape=(4,), dtype=int32)\n",
            "tf.Tensor([3 2 1 3 2 1 1 0], shape=(8,), dtype=int32)\n",
            "tf.Tensor([0 2], shape=(2,), dtype=int32)\n",
            "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Indexing\n",
        "x = tf.constant([0, 1, 1, 2, 3, 1, 2, 3])\n",
        "print(x[:])\n",
        "print(x[1:])\n",
        "print(x[1:3])\n",
        "print(x[::2])\n",
        "print(x[::-1])\n",
        "\n",
        "indices = tf.constant([0, 3])\n",
        "x_indices = tf.gather(x, indices)\n",
        "print(x_indices)\n",
        "\n",
        "x = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "print(x[0, :])\n",
        "print(x[0:2, :])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c02b5a45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c02b5a45",
        "outputId": "87148817-2fa3-468d-b61b-e9c3d51ce797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]], shape=(3, 3), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0 3 6]\n",
            " [1 4 7]\n",
            " [2 5 8]], shape=(3, 3), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]], shape=(3, 3), dtype=int32)\n",
            "tf.Tensor(\n",
            "[-1.3083701   0.5643746  -1.4199505  -0.47139707 -1.0932127  -0.6521097\n",
            "  0.8161861  -0.9095208   0.21995175 -1.1006311  -2.7728727  -0.5768039\n",
            " -2.7716784  -1.2200434  -0.47228888  0.06409699  1.5177748  -0.08468293\n",
            "  1.6347823   1.263455    1.2362937   1.7652506   0.516708   -0.78091156\n",
            " -1.9266231   1.1274539  -0.38541353 -0.13980883 -0.30654633 -1.5262358\n",
            "  0.06801758 -0.01412568 -0.65526384  0.2340061  -0.08360461  1.2987269\n",
            " -0.28258526 -1.0690365   0.20892313  3.3006997   0.06374627  0.80080545\n",
            "  0.8203447   0.1281679  -1.0913788  -0.9171942   0.553912   -0.21799463\n",
            "  1.768779   -0.26310885 -1.022221   -0.8987734   0.30104688  1.0012401\n",
            "  1.2380235   0.07277723 -0.08580884 -0.46358502 -1.3307132   0.48800862\n",
            " -0.9965649  -0.7107192   0.06379985  0.40490502  0.4805791  -0.22470218\n",
            "  0.15298972 -0.8600396  -2.164308    0.60801363  2.1278327   0.1305198\n",
            " -1.3190343  -0.11581818 -0.8534972 ], shape=(75,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Reshaping\n",
        "x = tf.range(9)\n",
        "print(x)\n",
        "\n",
        "x = tf.reshape(x, (3, 3))\n",
        "print(x)\n",
        "\n",
        "x = tf.transpose(x, perm=[1, 0])\n",
        "print(x)\n",
        "\n",
        "x = tf.transpose(x, perm=[1, 0])\n",
        "print(x)\n",
        "\n",
        "x = tf.random.normal((5,5,3))\n",
        "x = tf.reshape(x, [-1,])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.array(tf.range(9)).reshape(-1,1)"
      ],
      "metadata": {
        "id": "BIJgDZEfHQHS"
      },
      "id": "BIJgDZEfHQHS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "445b1cce",
      "metadata": {
        "id": "445b1cce"
      },
      "source": [
        "# Neural Networks with Sequential and Functional API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffcfebb7",
      "metadata": {
        "id": "ffcfebb7",
        "outputId": "097e719a-0a49-48ef-dc9b-c03480a27e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aec840f",
      "metadata": {
        "id": "4aec840f",
        "outputId": "f17af679-9869-483c-a8ed-defe7bfcb6bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 5s - loss: 0.1842 - accuracy: 0.9437 - 5s/epoch - 3ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 4s - loss: 0.0786 - accuracy: 0.9749 - 4s/epoch - 2ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 5s - loss: 0.0554 - accuracy: 0.9826 - 5s/epoch - 2ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 7s - loss: 0.0431 - accuracy: 0.9860 - 7s/epoch - 4ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 7s - loss: 0.0328 - accuracy: 0.9891 - 7s/epoch - 4ms/step\n",
            "313/313 - 1s - loss: 0.0982 - accuracy: 0.9743 - 1s/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09817493706941605, 0.9743000268936157]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Sequential API (Very convenient, not very flexible)\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28 * 28)),\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(256, activation=\"relu\"),\n",
        "        layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    #our last layer doesnot implement softmax so we set logits=True\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3055ba1d",
      "metadata": {
        "id": "3055ba1d",
        "outputId": "c667deef-9f82-4e23-a9e1-f4cab8d42f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " my_layer (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 8s - loss: 0.1859 - accuracy: 0.9429 - 8s/epoch - 4ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 7s - loss: 0.0807 - accuracy: 0.9745 - 7s/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 6s - loss: 0.0536 - accuracy: 0.9829 - 6s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 6s - loss: 0.0424 - accuracy: 0.9859 - 6s/epoch - 3ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 7s - loss: 0.0316 - accuracy: 0.9900 - 7s/epoch - 4ms/step\n",
            "*************\n",
            "313/313 - 1s - loss: 0.0834 - accuracy: 0.9790 - 920ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08336592465639114, 0.9789999723434448]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Another way of implementing Sequential API\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(784)))\n",
        "model.add(layers.Dense(512, activation=\"relu\"))\n",
        "model.add(layers.Dense(256, activation=\"relu\", name=\"my_layer\"))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    #our last layer doesnot implement softmax so we set logits=True\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "print(\"*************\")\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff39a9b9",
      "metadata": {
        "id": "ff39a9b9",
        "outputId": "264c16da-7461-4db5-db86-d36d2d96720e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " first_layer (Dense)         (None, 512)               401920    \n",
            "                                                                 \n",
            " second_layer (Dense)        (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 - 5s - loss: 0.1832 - accuracy: 0.9443 - 5s/epoch - 3ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 4s - loss: 0.0814 - accuracy: 0.9750 - 4s/epoch - 2ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 4s - loss: 0.0546 - accuracy: 0.9829 - 4s/epoch - 2ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 4s - loss: 0.0402 - accuracy: 0.9869 - 4s/epoch - 2ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 4s - loss: 0.0338 - accuracy: 0.9890 - 4s/epoch - 2ms/step\n",
            "313/313 - 1s - loss: 0.0813 - accuracy: 0.9795 - 856ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08131862431764603, 0.9794999957084656]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Functional API (A bit more flexible)\n",
        "# with ADAM Optimizer\n",
        "\n",
        "inputs = keras.Input(shape=(784))\n",
        "x1 = layers.Dense(512, activation=\"relu\", name=\"first_layer\")(inputs)\n",
        "x2 = layers.Dense(256, activation=\"relu\", name=\"second_layer\")(x1)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x2)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce369e76",
      "metadata": {
        "id": "ce369e76",
        "outputId": "6ef6a845-258f-47c0-a8e5-3d15251ae5a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " first_layer (Dense)         (None, 512)               401920    \n",
            "                                                                 \n",
            " second_layer (Dense)        (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1875/1875 - 4s - loss: 1.6357 - accuracy: 0.6284 - 4s/epoch - 2ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 4s - loss: 0.7830 - accuracy: 0.8334 - 4s/epoch - 2ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 4s - loss: 0.5435 - accuracy: 0.8674 - 4s/epoch - 2ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 4s - loss: 0.4521 - accuracy: 0.8834 - 4s/epoch - 2ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 4s - loss: 0.4032 - accuracy: 0.8925 - 4s/epoch - 2ms/step\n",
            "313/313 - 1s - loss: 0.3680 - accuracy: 0.9002 - 1s/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3680301904678345, 0.9002000093460083]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#with SGD optimizer\n",
        "inputs = keras.Input(shape=(784))\n",
        "x = layers.Dense(512, activation=\"relu\", name=\"first_layer\")(inputs)\n",
        "x = layers.Dense(256, activation=\"relu\", name=\"second_layer\")(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.001, momentum=0.0, nesterov=False, name=\"SGD\"),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1c4858f",
      "metadata": {
        "id": "a1c4858f",
        "outputId": "2497c24e-9c91-4481-9476-e56f8520c819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " first_layer (Dense)         (None, 512)               401920    \n",
            "                                                                 \n",
            " second_layer (Dense)        (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1875/1875 - 8s - loss: 0.1874 - accuracy: 0.9447 - 8s/epoch - 4ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 6s - loss: 0.0957 - accuracy: 0.9742 - 6s/epoch - 3ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 6s - loss: 0.0750 - accuracy: 0.9809 - 6s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 5s - loss: 0.0633 - accuracy: 0.9846 - 5s/epoch - 3ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 5s - loss: 0.0574 - accuracy: 0.9866 - 5s/epoch - 3ms/step\n",
            "313/313 - 1s - loss: 0.1246 - accuracy: 0.9770 - 859ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12462718784809113, 0.9769999980926514]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# RMSProp\n",
        "inputs = keras.Input(shape=(784))\n",
        "x = layers.Dense(512, activation=\"relu\", name=\"first_layer\")(inputs)\n",
        "x = layers.Dense(256, activation=\"relu\", name=\"second_layer\")(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=keras.optimizers.RMSprop(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-07,\n",
        "    centered=False,\n",
        "    name=\"RMSprop\",\n",
        "    ),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f92e634f",
      "metadata": {
        "id": "f92e634f",
        "outputId": "3ce81225-b9d5-4684-df72-619999c2d0ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " first_layer (Dense)         (None, 512)               401920    \n",
            "                                                                 \n",
            " second_layer (Dense)        (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1875/1875 - 5s - loss: 1.0121 - accuracy: 0.7788 - 5s/epoch - 3ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 4s - loss: 0.4404 - accuracy: 0.8868 - 4s/epoch - 2ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 4s - loss: 0.3611 - accuracy: 0.9026 - 4s/epoch - 2ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 5s - loss: 0.3240 - accuracy: 0.9105 - 5s/epoch - 2ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 5s - loss: 0.3001 - accuracy: 0.9167 - 5s/epoch - 2ms/step\n",
            "313/313 - 1s - loss: 0.2777 - accuracy: 0.9223 - 855ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2776957154273987, 0.9222999811172485]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Functional API with ADAgrad\n",
        "#Adagrad\n",
        "inputs = keras.Input(shape=(784))\n",
        "x = layers.Dense(512, activation=\"relu\", name=\"first_layer\")(inputs)\n",
        "x = layers.Dense(256, activation=\"relu\", name=\"second_layer\")(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=keras.optimizers.Adagrad(\n",
        "    learning_rate=0.001,\n",
        "    initial_accumulator_value=0.1,\n",
        "    epsilon=1e-07,\n",
        "    name=\"Adagrad\",\n",
        "),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fbf9c25",
      "metadata": {
        "id": "4fbf9c25"
      },
      "source": [
        "# CNN with Sequential and Functional API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "760fb3dd",
      "metadata": {
        "id": "760fb3dd",
        "outputId": "87a8e410-cfc0-4d18-9118-6d43d6942423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f3a6d1",
      "metadata": {
        "id": "04f3a6d1",
        "outputId": "a8d32e4b-46db-433f-ecdc-547f7ff60a16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                65600     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122,570\n",
            "Trainable params: 122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "782/782 - 7s - loss: 1.5779 - accuracy: 0.4278 - 7s/epoch - 9ms/step\n",
            "Epoch 2/5\n",
            "782/782 - 5s - loss: 1.2133 - accuracy: 0.5655 - 5s/epoch - 6ms/step\n",
            "Epoch 3/5\n",
            "782/782 - 5s - loss: 1.0621 - accuracy: 0.6236 - 5s/epoch - 6ms/step\n",
            "Epoch 4/5\n",
            "782/782 - 5s - loss: 0.9603 - accuracy: 0.6616 - 5s/epoch - 6ms/step\n",
            "Epoch 5/5\n",
            "782/782 - 5s - loss: 0.8882 - accuracy: 0.6891 - 5s/epoch - 6ms/step\n",
            "157/157 - 1s - loss: 0.9276 - accuracy: 0.6820 - 683ms/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9275500774383545, 0.6819999814033508]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(32, 32, 3)),\n",
        "        layers.Conv2D(32, (3,3), padding=\"valid\", activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN with Functional API and BatchNormalization"
      ],
      "metadata": {
        "id": "s6FKmb2bZYEs"
      },
      "id": "s6FKmb2bZYEs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0a95fd3",
      "metadata": {
        "id": "e0a95fd3",
        "outputId": "123e0fd8-8f92-4157-9ba4-2daf6a371272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 30, 30, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " tf.nn.relu (TFOpLambda)     (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 13, 13, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " tf.nn.relu_1 (TFOpLambda)   (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4, 4, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " tf.nn.relu_2 (TFOpLambda)   (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                131136    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225,930\n",
            "Trainable params: 225,482\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "782/782 - 7s - loss: 1.2554 - accuracy: 0.5528 - 7s/epoch - 9ms/step\n",
            "Epoch 2/5\n",
            "782/782 - 6s - loss: 0.8913 - accuracy: 0.6855 - 6s/epoch - 8ms/step\n",
            "Epoch 3/5\n",
            "782/782 - 6s - loss: 0.7435 - accuracy: 0.7419 - 6s/epoch - 8ms/step\n",
            "Epoch 4/5\n",
            "782/782 - 6s - loss: 0.6439 - accuracy: 0.7748 - 6s/epoch - 8ms/step\n",
            "Epoch 5/5\n",
            "782/782 - 6s - loss: 0.5629 - accuracy: 0.8005 - 6s/epoch - 8ms/step\n",
            "157/157 - 1s - loss: 1.0395 - accuracy: 0.6651 - 766ms/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.039521336555481, 0.6650999784469604]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "def my_model():\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(32, 3)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(10)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = my_model()\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ea51e9b",
      "metadata": {
        "id": "4ea51e9b"
      },
      "source": [
        "# Adding Regularization with L2 and Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f5cc9b",
      "metadata": {
        "id": "16f5cc9b",
        "outputId": "f3012d13-83b0-4ac4-c042-fb775d95abb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " tf.nn.relu_3 (TFOpLambda)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " tf.nn.relu_4 (TFOpLambda)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " tf.nn.relu_5 (TFOpLambda)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                524352    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 619,146\n",
            "Trainable params: 618,698\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 - 9s - loss: 3.0089 - accuracy: 0.3438 - 9s/epoch - 11ms/step\n",
            "Epoch 2/5\n",
            "782/782 - 8s - loss: 1.9293 - accuracy: 0.4534 - 8s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "782/782 - 8s - loss: 1.6321 - accuracy: 0.5158 - 8s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "782/782 - 8s - loss: 1.4986 - accuracy: 0.5496 - 8s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "782/782 - 8s - loss: 1.4284 - accuracy: 0.5688 - 8s/epoch - 10ms/step\n",
            "157/157 - 1s - loss: 1.2805 - accuracy: 0.6257 - 942ms/epoch - 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2804886102676392, 0.6256999969482422]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from tensorflow.keras import layers, regularizers\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "\n",
        "def my_model():\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(32, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(\n",
        "        inputs\n",
        "    )\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(\n",
        "        x\n",
        "    )\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(\n",
        "        128, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01),)(\n",
        "        x\n",
        "    )\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(10)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = my_model()\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNNs, GRUs, LSTMs and Bidirectionality"
      ],
      "metadata": {
        "id": "LrBCp50gaAm1"
      },
      "id": "LrBCp50gaAm1"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "x_train = x_train.reshape([-1, 28, 28]).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape([-1, 28, 28]).astype(\"float32\") / 255.0\n",
        "\n",
        "print(\"*****\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSikeEhScIV3",
        "outputId": "e42b1c2f-a2f0-4039-a781-87af89e0431a"
      },
      "id": "rSikeEhScIV3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "*****\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimpleRNN"
      ],
      "metadata": {
        "id": "HGH7xmerj3O0"
      },
      "id": "HGH7xmerj3O0"
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28)))\n",
        "model.add(layers.SimpleRNN(256, return_sequences=True, activation=\"relu\"))\n",
        "model.add(layers.SimpleRNN(256, activation=\"relu\"))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zwYRdQ1kAcK",
        "outputId": "a3409c1b-98dd-45a6-d015-13380deeb507"
      },
      "id": "-zwYRdQ1kAcK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_2 (SimpleRNN)    (None, None, 256)         72960     \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 206,858\n",
            "Trainable params: 206,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 - 64s - loss: 0.3388 - accuracy: 0.8909 - 64s/epoch - 136ms/step\n",
            "Epoch 2/5\n",
            "469/469 - 46s - loss: 0.1122 - accuracy: 0.9670 - 46s/epoch - 98ms/step\n",
            "Epoch 3/5\n",
            "469/469 - 36s - loss: 0.0867 - accuracy: 0.9753 - 36s/epoch - 78ms/step\n",
            "Epoch 4/5\n",
            "469/469 - 36s - loss: 0.0717 - accuracy: 0.9800 - 36s/epoch - 78ms/step\n",
            "Epoch 5/5\n",
            "469/469 - 36s - loss: 0.0691 - accuracy: 0.9802 - 36s/epoch - 77ms/step\n",
            "157/157 - 2s - loss: 0.0578 - accuracy: 0.9840 - 2s/epoch - 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.057846441864967346, 0.984000027179718]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Default activation function for RNN is \"tanh\"\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28)))\n",
        "model.add(layers.SimpleRNN(256, return_sequences=True, activation=\"tanh\"))\n",
        "model.add(layers.SimpleRNN(256, activation=\"tanh\"))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFgDib8ukGzC",
        "outputId": "64fa9fa3-5e16-4038-fad5-d0f029bdcc86"
      },
      "id": "MFgDib8ukGzC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_4 (SimpleRNN)    (None, None, 256)         72960     \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 206,858\n",
            "Trainable params: 206,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n",
            "157/157 - 2s - loss: 0.1370 - accuracy: 0.9612 - 2s/epoch - 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13700330257415771, 0.9611999988555908]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN with GRU"
      ],
      "metadata": {
        "id": "SSdh8jcls-pi"
      },
      "id": "SSdh8jcls-pi"
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28)))\n",
        "model.add(layers.GRU(256, return_sequences=True, activation=\"tanh\"))\n",
        "model.add(layers.GRU(256, activation=\"tanh\"))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ByS3gHls8mF",
        "outputId": "ef8aaf01-bd47-474f-8349-ff2d9c1b66b8"
      },
      "id": "6ByS3gHls8mF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, None, 256)         219648    \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 256)               394752    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 616,970\n",
            "Trainable params: 616,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938/938 - 136s - loss: 0.2891 - accuracy: 0.9030 - 136s/epoch - 145ms/step\n",
            "Epoch 2/5\n",
            "938/938 - 154s - loss: 0.0743 - accuracy: 0.9770 - 154s/epoch - 164ms/step\n",
            "Epoch 3/5\n",
            "938/938 - 106s - loss: 0.0495 - accuracy: 0.9853 - 106s/epoch - 113ms/step\n",
            "Epoch 4/5\n",
            "938/938 - 106s - loss: 0.0389 - accuracy: 0.9880 - 106s/epoch - 113ms/step\n",
            "Epoch 5/5\n",
            "938/938 - 107s - loss: 0.0318 - accuracy: 0.9902 - 107s/epoch - 114ms/step\n",
            "157/157 - 3s - loss: 0.0446 - accuracy: 0.9860 - 3s/epoch - 16ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.044587623327970505, 0.9860000014305115]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNN with LSTM"
      ],
      "metadata": {
        "id": "BJ6ZCGZ3t3Rn"
      },
      "id": "BJ6ZCGZ3t3Rn"
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28)))\n",
        "model.add(layers.LSTM(256, return_sequences=True, activation=\"tanh\"))\n",
        "model.add(layers.LSTM(256, activation=\"tanh\"))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKZusEdmt_a1",
        "outputId": "f6d13a48-4233-494a-c77f-f816a85a86c4"
      },
      "id": "wKZusEdmt_a1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, None, 256)         291840    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 819,722\n",
            "Trainable params: 819,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938/938 - 22s - loss: 0.3037 - accuracy: 0.9005 - 22s/epoch - 24ms/step\n",
            "Epoch 2/5\n",
            "938/938 - 18s - loss: 0.0873 - accuracy: 0.9723 - 18s/epoch - 19ms/step\n",
            "Epoch 3/5\n",
            "938/938 - 18s - loss: 0.0591 - accuracy: 0.9818 - 18s/epoch - 19ms/step\n",
            "Epoch 4/5\n",
            "938/938 - 18s - loss: 0.0451 - accuracy: 0.9864 - 18s/epoch - 19ms/step\n",
            "Epoch 5/5\n",
            "938/938 - 18s - loss: 0.0382 - accuracy: 0.9879 - 18s/epoch - 19ms/step\n",
            "157/157 - 2s - loss: 0.0608 - accuracy: 0.9822 - 2s/epoch - 15ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06082245334982872, 0.982200026512146]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN with bidirectional layers on 1st LSTM layer"
      ],
      "metadata": {
        "id": "ERYZi6Q8wmzt"
      },
      "id": "ERYZi6Q8wmzt"
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28)))\n",
        "model.add(\n",
        "    layers.Bidirectional(layers.LSTM(256, return_sequences=True, activation=\"relu\"))\n",
        ")\n",
        "model.add(layers.LSTM(256, name=\"lstm_layer2\"))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OTac78owa65",
        "outputId": "03ac4ace-15b6-451a-8a8f-92c8eba24ace"
      },
      "id": "3OTac78owa65",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, None, 512)        583680    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " lstm_layer2 (LSTM)          (None, 256)               787456    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,373,706\n",
            "Trainable params: 1,373,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 - 197s - loss: 0.2749 - accuracy: 0.9111 - 197s/epoch - 210ms/step\n",
            "Epoch 2/5\n",
            "938/938 - 161s - loss: 0.0848 - accuracy: 0.9742 - 161s/epoch - 172ms/step\n",
            "Epoch 3/5\n",
            "938/938 - 159s - loss: 0.0596 - accuracy: 0.9823 - 159s/epoch - 170ms/step\n",
            "Epoch 4/5\n",
            "938/938 - 159s - loss: 0.0485 - accuracy: 0.9852 - 159s/epoch - 170ms/step\n",
            "Epoch 5/5\n",
            "938/938 - 163s - loss: 0.0376 - accuracy: 0.9885 - 163s/epoch - 173ms/step\n",
            "157/157 - 4s - loss: 0.0458 - accuracy: 0.9864 - 4s/epoch - 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04581201821565628, 0.9864000082015991]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN with Bidirectional Layyer on both the LSTM Layers"
      ],
      "metadata": {
        "id": "QwVg39TbwxbM"
      },
      "id": "QwVg39TbwxbM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cf9d5d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28256fa-4fec-4f27-b781-16a583415cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (None, None, 512)        583680    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 512)              1574912   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,163,722\n",
            "Trainable params: 2,163,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938/938 - 179s - loss: 0.2545 - accuracy: 0.9162 - 179s/epoch - 191ms/step\n",
            "Epoch 2/10\n",
            "938/938 - 172s - loss: 0.0742 - accuracy: 0.9764 - 172s/epoch - 183ms/step\n",
            "Epoch 3/10\n",
            "938/938 - 174s - loss: 0.0528 - accuracy: 0.9834 - 174s/epoch - 185ms/step\n",
            "Epoch 4/10\n",
            "938/938 - 171s - loss: 0.0410 - accuracy: 0.9871 - 171s/epoch - 182ms/step\n",
            "Epoch 5/10\n",
            "938/938 - 173s - loss: 0.0343 - accuracy: 0.9891 - 173s/epoch - 184ms/step\n",
            "Epoch 6/10\n",
            "938/938 - 175s - loss: 0.0309 - accuracy: 0.9905 - 175s/epoch - 187ms/step\n",
            "Epoch 7/10\n",
            "938/938 - 178s - loss: 0.0242 - accuracy: 0.9924 - 178s/epoch - 190ms/step\n",
            "Epoch 8/10\n",
            "938/938 - 174s - loss: 0.0222 - accuracy: 0.9928 - 174s/epoch - 185ms/step\n",
            "Epoch 9/10\n",
            "938/938 - 174s - loss: 0.0196 - accuracy: 0.9938 - 174s/epoch - 186ms/step\n",
            "Epoch 10/10\n",
            "938/938 - 176s - loss: 0.0190 - accuracy: 0.9938 - 176s/epoch - 188ms/step\n",
            "157/157 - 5s - loss: 0.0436 - accuracy: 0.9879 - 5s/epoch - 29ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.043606992810964584, 0.9879000186920166]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(None, 28)))\n",
        "model.add(\n",
        "    layers.Bidirectional(layers.LSTM(256, return_sequences=True, activation=\"relu\"))\n",
        ")\n",
        "model.add(layers.Bidirectional(layers.LSTM(256, name=\"lstm_layer2\")))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "id": "0cf9d5d3"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9v9AkISw6U3"
      },
      "id": "F9v9AkISw6U3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}