{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importing libs and data"
      ],
      "metadata": {
        "id": "GDmnul80Xg1R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Ng690uXXxz",
        "outputId": "ca747fde-c670-4c44-b84e-a9e1b86c6398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# # To Avoid GPU errors\n",
        "# physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. How to save and load model weights\n",
        "# 2. Save and loading entire model (Serializing model)\n",
        "#   - Saves weights\n",
        "#   - Model architecture\n",
        "#   - Training Configuration (model.compile())\n",
        "#   - Optimizer and states\n",
        "\n",
        "model1 = keras.Sequential([layers.Dense(64, activation=\"relu\"), layers.Dense(10)])\n",
        "\n",
        "inputs = keras.Input(784)\n",
        "x = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "outputs = layers.Dense(10)(x)\n",
        "model2 = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "class MyModel(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = layers.Dense(64, activation=\"relu\")\n",
        "        self.dense2 = layers.Dense(10)\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        x = tf.nn.relu(self.dense1(input_tensor))\n",
        "        return self.dense2(x)\n",
        "\n",
        "\n",
        "# SavedModel format or HDF5 format\n",
        "model3 = MyModel()\n",
        "# model = keras.models.load_model('saved_model/')\n",
        "# model.load_weights('checkpoint_folder/')\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=2, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)\n",
        "# model.save_weights('checkpoint_folder/')\n",
        "model.save(\"saved_model/\")"
      ],
      "metadata": {
        "id": "aCO3Q6guXkiC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}