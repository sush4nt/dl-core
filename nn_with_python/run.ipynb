{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c268fa2-808d-436b-ad5e-7cbedcc8e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn.datasets as datasets\n",
    "from nn import NeuralNetwork\n",
    "from optimizer import Optimizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2161ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4031b65-87ce-46e9-b440-4b8b5c5b79ba",
   "metadata": {},
   "source": [
    "## 1. Classification Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabeb137-740e-41d8-b8ed-dc24706ae12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a binary classification test\n"
     ]
    }
   ],
   "source": [
    "# test run for binary classification problem:\n",
    "np.random.seed(3)\n",
    "print('Running a binary classification test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c16b81-6fd5-4573-aa7e-dbd9b368be8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (10, 30000)\n",
      "Output shape:  (1, 30000)\n"
     ]
    }
   ],
   "source": [
    "data = datasets.make_classification(n_samples=30000,n_features=10,n_classes=2)\n",
    "X = data[0].T\n",
    "Y = (data[1].reshape(30000,1)).T\n",
    "\n",
    "print(\"Input shape: \", X.shape)\n",
    "print(\"Output shape: \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aaeb286-cff9-46f8-979f-96aa83200be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,20 ) |  activation: relu | No of parameters: 200\n",
      "----->> Layer 2: ( 20,1 ) |  activation: sigmoid | No of parameters: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: gradient-descent-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  0 :  0.7462\n",
      "----->> Loss at  100 :  0.24641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for gradient descent \n",
      " accuracy =  91.65\n"
     ]
    }
   ],
   "source": [
    "#Generate sample binary classification data\n",
    "net = NeuralNetwork(\n",
    "                    layer_dimensions=[10,20,1],\n",
    "                    activations=['relu','sigmoid']\n",
    "                   )\n",
    "net.cost_function = 'CrossEntropyLoss'\n",
    "print(net)\n",
    "\n",
    "#Optimize using standard gradient descenet\n",
    "optim = Optimizer.gradientDescentOptimizer\n",
    "optim(input=X,\n",
    "      mappings=Y,\n",
    "      net=net,\n",
    "      alpha=0.07,\n",
    "      epoch=200,\n",
    "      lamb=0.05,\n",
    "      print_at=100)\n",
    "sys.stdout.flush()\n",
    "logger.info('-----Optimization Finished. Weights updated-----')\n",
    "output = net.forward(X)\n",
    "\n",
    "#Convert the probabilities to output values\n",
    "output = 1*(output>=0.5)\n",
    "accuracy = np.sum(output==Y)/30000\n",
    "print()\n",
    "print('for gradient descent \\n accuracy = ' , np.round(accuracy*100,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b155e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_nn(layer_dimensions, activations, cost_function, optimizer, optimizer_params):\n",
    "    net = NeuralNetwork(\n",
    "                    layer_dimensions=layer_dimensions,\n",
    "                    activations=activations\n",
    "                   )\n",
    "    net.cost_function = cost_function\n",
    "    print(net)\n",
    "    optimizer(input=X,\n",
    "            mappings=Y,\n",
    "            net=net,\n",
    "            **optimizer_params)\n",
    "    sys.stdout.flush()\n",
    "    logger.info('-----Optimization Finished. Weights updated-----')\n",
    "    output = net.forward(X)\n",
    "\n",
    "    #Convert the probabilities to output values\n",
    "    output = 1*(output>=0.5)\n",
    "    accuracy = np.sum(output==Y)/30000\n",
    "    print()\n",
    "    print('for ', optimizer, '\\n accuracy = ' , np.round(accuracy*100,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69fb2505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,20 ) |  activation: relu | No of parameters: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 2: ( 20,1 ) |  activation: sigmoid | No of parameters: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: gradient-descent-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  0 :  0.73588\n",
      "----->> Loss at  100 :  0.23987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for  <function Optimizer.gradientDescentOptimizer at 0xffff1ffa05e0> \n",
      " accuracy =  91.84667\n"
     ]
    }
   ],
   "source": [
    "execute_nn([10,20,1], ['relu','sigmoid'], 'CrossEntropyLoss', Optimizer.gradientDescentOptimizer, {'alpha':0.07, 'epoch':200, 'lamb':0.05, 'print_at':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8592f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,20 ) |  activation: relu | No of parameters: 200\n",
      "----->> Layer 2: ( 20,30 ) |  activation: relu | No of parameters: 600\n",
      "----->> Layer 3: ( 30,20 ) |  activation: relu | No of parameters: 600\n",
      "----->> Layer 4: ( 20,1 ) |  activation: sigmoid | No of parameters: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: gradient-descent-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  0 :  0.69976\n",
      "----->> Loss at  100 :  0.24731\n",
      "----->> Loss at  200 :  0.21437\n",
      "----->> Loss at  300 :  0.20525\n",
      "----->> Loss at  400 :  0.1994\n",
      "----->> Loss at  500 :  0.19487\n",
      "----->> Loss at  600 :  0.19089\n",
      "----->> Loss at  700 :  0.18707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for  <function Optimizer.gradientDescentOptimizer at 0xffff1ffa05e0> \n",
      " accuracy =  93.53\n"
     ]
    }
   ],
   "source": [
    "execute_nn([10, 20, 30, 20,1], ['relu', 'relu', 'relu','sigmoid'], 'CrossEntropyLoss', Optimizer.gradientDescentOptimizer, {'alpha':0.07, 'epoch':800, 'lamb':0.05, 'print_at':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6605dfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,20 ) |  activation: relu | No of parameters: 200\n",
      "----->> Layer 2: ( 20,1 ) |  activation: sigmoid | No of parameters: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: stochastic-gradient-descent-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  1 :  0.20671\n",
      "----->> Loss at  2 :  0.1975\n",
      "----->> Loss at  3 :  0.19323\n",
      "----->> Loss at  4 :  0.19063\n",
      "----->> Loss at  5 :  0.18871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for  <function Optimizer.SGDOptimizer at 0xffff1ffa0670> \n",
      " accuracy =  93.08\n"
     ]
    }
   ],
   "source": [
    "execute_nn([10,20,1], ['relu','sigmoid'], 'CrossEntropyLoss', Optimizer.SGDOptimizer, {'alpha':0.07, 'epoch':5, 'lamb':0.05, 'print_at':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf2fcde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,20 ) |  activation: relu | No of parameters: 200\n",
      "----->> Layer 2: ( 20,1 ) |  activation: sigmoid | No of parameters: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: stochastic-gradient-descent-with-momentum-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  1 :  0.22373\n",
      "----->> Loss at  2 :  0.20854\n",
      "----->> Loss at  3 :  0.19906\n",
      "----->> Loss at  4 :  0.19532\n",
      "----->> Loss at  5 :  0.19294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for  <function Optimizer.SGDOptimizer at 0xffff1ffa0670> \n",
      " accuracy =  92.93\n"
     ]
    }
   ],
   "source": [
    "execute_nn([10,20,1], ['relu','sigmoid'], 'CrossEntropyLoss', Optimizer.SGDOptimizer, {'alpha':0.07, 'mini_batch_size':128, 'epoch':5, 'lamb':0.05, 'print_at':1, 'momentum':0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86d9984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,20 ) |  activation: relu | No of parameters: 200\n",
      "----->> Layer 2: ( 20,1 ) |  activation: sigmoid | No of parameters: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: adaptive-momentum-estimation(ADAM)-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  5 :  0.226\n",
      "----->> Loss at  10 :  0.23369\n",
      "----->> Loss at  15 :  0.21778\n",
      "----->> Loss at  20 :  0.20014\n",
      "----->> Loss at  25 :  0.18765\n",
      "----->> Loss at  30 :  0.17705\n",
      "----->> Loss at  35 :  0.16599\n",
      "----->> Loss at  40 :  0.15623\n",
      "----->> Loss at  45 :  0.14716\n",
      "----->> Loss at  50 :  0.14028\n",
      "----->> Loss at  55 :  0.13487\n",
      "----->> Loss at  60 :  0.13172\n",
      "----->> Loss at  65 :  0.13004\n",
      "----->> Loss at  70 :  0.12821\n",
      "----->> Loss at  75 :  0.12626\n",
      "----->> Loss at  80 :  0.12461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for  <function Optimizer.AdamOptimizer at 0xffff1ffa0700> \n",
      " accuracy =  95.93\n"
     ]
    }
   ],
   "source": [
    "execute_nn([10,20,1], ['relu','sigmoid'], 'CrossEntropyLoss', Optimizer.AdamOptimizer, {'alpha':0.07, 'epoch':80, 'lamb':0.05, 'print_at':5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091868f7-4461-4be7-b414-db9b23ca76c8",
   "metadata": {},
   "source": [
    "## 2. Regression Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6571cc6d-0e34-42a3-8d8e-cbbc8bf7bef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a regression test\n"
     ]
    }
   ],
   "source": [
    "#test run for regresssion problem:\n",
    "print('Running a regression test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a095a98d-a4b7-430c-8943-17c60626022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (10, 442)\n",
      "Output shape:  (1, 442)\n"
     ]
    }
   ],
   "source": [
    "X, Y = datasets.load_diabetes(return_X_y=True)\n",
    "X = X.T\n",
    "Y = Y.reshape(442,1).T\n",
    "\n",
    "print(\"Input shape: \", X.shape)\n",
    "print(\"Output shape: \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c63ecdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_reg(layer_dimensions, activations, cost_function, optimizer, optimizer_params):\n",
    "    net = NeuralNetwork(\n",
    "                    layer_dimensions=layer_dimensions,\n",
    "                    activations=activations\n",
    "                   )\n",
    "    net.cost_function = cost_function\n",
    "    print(net)\n",
    "    optimizer(input=X,\n",
    "            mappings=Y,\n",
    "            net=net,\n",
    "            **optimizer_params)\n",
    "    sys.stdout.flush()\n",
    "    logger.info('-----Optimization Finished. Weights updated-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8757e81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,20 ) |  activation: relu | No of parameters: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: gradient-descent-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  0 :  14536.56151\n",
      "----->> Loss at  100 :  7911996.6847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    }
   ],
   "source": [
    "execute_reg([10,20,1], ['relu'], 'MSELoss', Optimizer.gradientDescentOptimizer, {'alpha':0.3, 'epoch':200, 'lamb':0.05, 'print_at':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "719f4320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,20 ) |  activation: relu | No of parameters: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: gradient-descent-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  0 :  14534.64899\n",
      "----->> Loss at  100 :  3013.90695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    }
   ],
   "source": [
    "execute_reg([10,20,1], ['relu'], 'MSELoss', Optimizer.gradientDescentOptimizer, {'alpha':0.03, 'epoch':200, 'lamb':0.05, 'print_at':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38d80c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,30 ) |  activation: relu | No of parameters: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: stochastic-gradient-descent-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  1 :  13505.24161\n",
      "----->> Loss at  2 :  9850.92164\n",
      "----->> Loss at  3 :  7465.10771\n",
      "----->> Loss at  4 :  6513.27805\n",
      "----->> Loss at  5 :  5286.34559\n",
      "----->> Loss at  6 :  4485.35934\n",
      "----->> Loss at  7 :  3962.44622\n",
      "----->> Loss at  8 :  3621.06933\n",
      "----->> Loss at  9 :  3398.20588\n",
      "----->> Loss at  10 :  3252.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    }
   ],
   "source": [
    "execute_reg([10,30,1], ['relu'], 'MSELoss', Optimizer.SGDOptimizer, {'alpha':0.03, 'epoch':10, 'lamb':0.05, 'print_at':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "275794b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,30 ) |  activation: relu | No of parameters: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: stochastic-gradient-descent-with-momentum-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  1 :  8559.87705\n",
      "----->> Loss at  2 :  3768.79593\n",
      "----->> Loss at  3 :  3153.77154\n",
      "----->> Loss at  4 :  2756.49579\n",
      "----->> Loss at  5 :  2293.91761\n",
      "----->> Loss at  6 :  1680.75102\n",
      "----->> Loss at  7 :  1753.32279\n",
      "----->> Loss at  8 :  1573.92763\n",
      "----->> Loss at  9 :  1551.9531\n",
      "----->> Loss at  10 :  1497.71696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    }
   ],
   "source": [
    "execute_reg([10,30,1], ['relu'], 'MSELoss', Optimizer.SGDOptimizer, {'alpha':0.03, 'epoch':10, 'lamb':0.05, 'print_at':1, 'momentum':0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9834f7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Initializing Weights-----\n",
      "INFO - -----Checking Activations-----\n",
      "INFO - -----Network Architecture-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->> Layer 1: ( 10,30 ) |  activation: relu | No of parameters: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimizer: adaptive-momentum-estimation(ADAM)-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----->> Loss at  1 :  14508.59525\n",
      "----->> Loss at  2 :  14470.87791\n",
      "----->> Loss at  3 :  14416.87952\n",
      "----->> Loss at  4 :  14345.14303\n",
      "----->> Loss at  5 :  14254.9099\n",
      "----->> Loss at  6 :  14145.15672\n",
      "----->> Loss at  7 :  14014.84114\n",
      "----->> Loss at  8 :  13863.20193\n",
      "----->> Loss at  9 :  13689.7356\n",
      "----->> Loss at  10 :  13494.17116\n",
      "----->> Loss at  11 :  13276.44062\n",
      "----->> Loss at  12 :  13036.69108\n",
      "----->> Loss at  13 :  12775.44886\n",
      "----->> Loss at  14 :  12493.39083\n",
      "----->> Loss at  15 :  12191.37233\n",
      "----->> Loss at  16 :  11870.43\n",
      "----->> Loss at  17 :  11531.76959\n",
      "----->> Loss at  18 :  11176.75319\n",
      "----->> Loss at  19 :  10806.88633\n",
      "----->> Loss at  20 :  10423.80494\n",
      "----->> Loss at  21 :  10029.26212\n",
      "----->> Loss at  22 :  9625.11456\n",
      "----->> Loss at  23 :  9213.30858\n",
      "----->> Loss at  24 :  8795.86547\n",
      "----->> Loss at  25 :  8374.86644\n",
      "----->> Loss at  26 :  7952.4369\n",
      "----->> Loss at  27 :  7530.73096\n",
      "----->> Loss at  28 :  7111.9162\n",
      "----->> Loss at  29 :  6698.15865\n",
      "----->> Loss at  30 :  6291.60706\n",
      "----->> Loss at  31 :  5894.37533\n",
      "----->> Loss at  32 :  5508.52285\n",
      "----->> Loss at  33 :  5136.03292\n",
      "----->> Loss at  34 :  4778.78941\n",
      "----->> Loss at  35 :  4438.55223\n",
      "----->> Loss at  36 :  4116.93154\n",
      "----->> Loss at  37 :  3815.36135\n",
      "----->> Loss at  38 :  3535.07293\n",
      "----->> Loss at  39 :  3277.06875\n",
      "----->> Loss at  40 :  3042.09783\n",
      "----->> Loss at  41 :  2830.63307\n",
      "----->> Loss at  42 :  2642.85146\n",
      "----->> Loss at  43 :  2478.61782\n",
      "----->> Loss at  44 :  2337.47335\n",
      "----->> Loss at  45 :  2218.63069\n",
      "----->> Loss at  46 :  2120.97731\n",
      "----->> Loss at  47 :  2043.08945\n",
      "----->> Loss at  48 :  1983.25829\n",
      "----->> Loss at  49 :  1939.5293\n",
      "----->> Loss at  50 :  1909.75498\n",
      "----->> Loss at  51 :  1891.65972\n",
      "----->> Loss at  52 :  1882.91411\n",
      "----->> Loss at  53 :  1881.21464\n",
      "----->> Loss at  54 :  1884.36363\n",
      "----->> Loss at  55 :  1890.34362\n",
      "----->> Loss at  56 :  1897.38053\n",
      "----->> Loss at  57 :  1903.9911\n",
      "----->> Loss at  58 :  1909.0113\n",
      "----->> Loss at  59 :  1911.6048\n",
      "----->> Loss at  60 :  1911.25231\n",
      "----->> Loss at  61 :  1907.72456\n",
      "----->> Loss at  62 :  1901.04266\n",
      "----->> Loss at  63 :  1891.4305\n",
      "----->> Loss at  64 :  1879.26355\n",
      "----->> Loss at  65 :  1865.01811\n",
      "----->> Loss at  66 :  1849.22427\n",
      "----->> Loss at  67 :  1832.4248\n",
      "----->> Loss at  68 :  1815.14145\n",
      "----->> Loss at  69 :  1797.84916\n",
      "----->> Loss at  70 :  1780.95807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - -----Optimization Finished. Weights updated-----\n"
     ]
    }
   ],
   "source": [
    "execute_reg([10,30,1], ['relu'], 'MSELoss', Optimizer.AdamOptimizer, {'alpha':0.03, 'epoch':70, 'lamb':0.05, 'print_at':1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
